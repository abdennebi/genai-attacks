{
  "$id": "$gai-technique/search_for_victims_publicly_available_code_repositories",
  "$schema": "../schema/technique.schema.json",
  "$type": "technique",
  "description": "Much like the Search for Victim's Publicly Available Research Materials, there is often ample research available on the vulnerabilities of common models. Once a target has been identified, an adversary will likely try to identify any pre-existing work that has been done for this class of models. This will include not only reading academic papers that may identify the particulars of a successful attack, but also identifying pre-existing implementations of those attacks. The adversary may obtain Adversarial ML Attack Implementations or develop their own Adversarial ML Attacks if necessary.",
  "external_references": [],
  "framework_references": [
    {
      "framework_id": "AML.T0001",
      "framework_name": "MITRE ATLAS",
      "href": "https://atlas.mitre.org/techniques/AML.T0001"
    }
  ],
  "name": "Search for Victim's Publicly Available Code Repositories",
  "object_references": [
    {
      "$id": "$gai-tactic/reconnaissance",
      "$type": "tactic",
      "description": "Gathering publicly available code repositories allows adversaries to understand how and where machine learning is utilized within a target organization, aiding in planning tailored attacks."
    }
  ]
}
