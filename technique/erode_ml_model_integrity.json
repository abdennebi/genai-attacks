{
  "$id": "$gai-technique/erode_ml_model_integrity",
  "$schema": "../schema/technique.schema.json",
  "$type": "technique",
  "description": "Adversaries may degrade the target model's performance with adversarial data inputs to erode confidence in the system over time. This can lead to the victim organization wasting time and money both attempting to fix the system and performing the tasks it was meant to automate by hand.",
  "external_references": [],
  "framework_references": [
    {
      "framework_id": "AML.T0031",
      "framework_name": "MITRE ATLAS",
      "href": "https://atlas.mitre.org/techniques/AML.T0031"
    }
  ],
  "name": "Erode ML Model Integrity",
  "object_references": [
    {
      "$id": "$gai-tactic/impact",
      "$type": "tactic",
      "description": "Compromising the integrity of machine learning models to produce incorrect or unreliable results."
    }
  ]
}
