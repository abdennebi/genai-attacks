{
  "$id": "$gai-technique/rag_poisoning",
  "$schema": "../schema/technique.schema.json",
  "$type": "technique",
  "description": "The adversary injects malicious content into data indexed by a RAG system to contaminate a future thread through RAG-based search results.",
  "external_references": [
    {
      "href": "https://en.wikipedia.org/wiki/Retrieval-augmented_generation",
      "source": "Wikipedia",
      "title": "Retrieval-augmented generation."
    },

    {
      "href": "https://arxiv.org/abs/2406.00083",
      "source": "arXiv",
      "title": "BadRAG: Identifying Vulnerabilities in Retrieval Augmented Generation of Large Language Models."
    },

    {
      "href": "https://arxiv.org/abs/2408.04870",
      "source": "arXiv",
      "title": "ConfusedPilot: Confused Deputy Risks in RAG-based LLMs."
    },

    {
      "href": "https://arxiv.org/abs/2402.07867",
      "source": "arXiv",
      "title": "PoisonedRAG: Knowledge Corruption Attacks to Retrieval-Augmented Generation of Large Language Models."
    }

  ],
  "framework_references": [],
  "name": "RAG Poisoning",
  "object_references": [
    {
      "$id": "$gai-tactic/initial_access",
      "$type": "tactic",
      "description": "An adversary can indirectly inject malicious content into a thread by contaminating RAG data."
    },
    {
      "$id": "$gai-entity/johann_rehberger",
      "$type": "entity",
      "description": "Demonstrated by"
    },
    {
      "$id": "$gai-entity/michael_bargury",
      "$type": "entity",
      "description": "Demonstrated by"
    },
    {
      "$id": "$gai-entity/tamir_ishay_sharbat",
      "$type": "entity",
      "description": "Demonstrated by"
    },
    {
      "$id": "$gai-entity/ayush_roychowdhury",
      "$type": "entity",
      "description": "Demonstrated by"
    }
  ]
}
